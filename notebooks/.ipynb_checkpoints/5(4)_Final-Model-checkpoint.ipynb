{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import  category_encoders as ce\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/notebooks/4_merged_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saima\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(data_path)\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['launched_at',  'status', 'days_to_deadline', 'goal',\n",
    "       'sub_category', 'category', 'blurb_length', 'location_country',  'rewards_mean', 'rewards_median',\n",
    "       'rewards_variance', 'rewards_SD', 'rewards_MIN', 'rewards_MAX' ,\n",
    "        'rewards_NUM', 'currency', 'launch_year', 'launch_month',\n",
    "        'deadline_year', 'deadline_month']\n",
    "target_encoding_cols = ['location_country' , 'currency' , 'category', 'sub_category']\n",
    "\n",
    "train_years =[2016, 2017  , 2018 , 2019]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_proc(df):\n",
    "    df = df[cols]\n",
    "    df= df.dropna(axis=0, subset=[\"rewards_MIN\"])\n",
    "    df= df.dropna(axis=0, subset=[\"blurb_length\"])\n",
    "    df.sort_values(\"launched_at\" , inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"launched_at\"]  = pd.to_datetime(df[\"launched_at\"]).dt.date\n",
    "    df.sort_values(\"launched_at\" , inplace=True)\n",
    "    df.drop(['launched_at', ] ,axis=1 , inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', inplace=True , axis=1)\n",
    "    \n",
    "    binarizer= LabelBinarizer()\n",
    "    df[\"status\"] = binarizer.fit_transform(df[\"status\"])\n",
    "    \n",
    "    \n",
    "    return df , binarizer\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_categ(df):\n",
    "    \n",
    "    encoder  = OneHotEncoder(sparse=False)\n",
    "    X_hot = encoder.fit_transform(df[ target_encoding_cols])\n",
    "    \n",
    "    onehotcols = []\n",
    "    for cat in encoder.categories_:\n",
    "        for col in cat:\n",
    "            onehotcols.append(col)\n",
    "            \n",
    "    X_hot = pd.DataFrame(X_hot , columns=onehotcols)\n",
    "    df =pd.concat([df , X_hot] , axis=1)\n",
    "    df.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    \n",
    "    \n",
    "    return df , encoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(df , train_years ):\n",
    "    \n",
    "    df_train = df[df['launch_year'].apply(lambda x: True if x in train_years else False)]\n",
    "    X_train , y_train = df_train.drop(\"status\" , axis=1) , df_train['status']\n",
    "    \n",
    "    return X_train , y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helmert_categ(df_train):\n",
    "    encoder = ce.HelmertEncoder(cols = target_encoding_cols , drop_invariant=True )\n",
    "    dfh = encoder.fit_transform(df_train[target_encoding_cols])\n",
    "    df_train = pd.concat([df_train , dfh], axis=1)\n",
    "    df_train.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    \n",
    "    return df_train , encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import operator\n",
    "\n",
    "def XG_train(X_train,  y_train):\n",
    "    \n",
    "    XG= XGBClassifier(n_estimators=150, random_state=3)\n",
    "    XG.fit(X_train, y_train)\n",
    "   \n",
    "    return XG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc , binarizer  = pre_proc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_onehot ,onehotencoder  = onehot_categ(df_proc)\n",
    "X_train_oh , y_train_oh= get_model_data(df_onehot , train_years )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw , y_train_hel  = get_model_data(df_proc , train_years)\n",
    "X_train_hel ,helmert_encoder  = helmert_categ(X_train_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_oh = XG_train(X_train_oh ,y_train_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hel = XG_train(X_train_hel ,y_train_hel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models and encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saima\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.externals import joblib\n",
    "def save_estimator(model , path):\n",
    "    try:\n",
    "        joblib.dump(model , path)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "        \n",
    "        \n",
    "    return \"Saved sucessfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sucessfully\n",
      "Saved sucessfully\n",
      "Saved sucessfully\n",
      "Saved sucessfully\n",
      "Saved sucessfully\n"
     ]
    }
   ],
   "source": [
    "print(save_estimator(model_oh , 'estimators/model_oh.sav'))\n",
    "print(save_estimator(model_hel , 'estimators/model_hel.sav'))\n",
    "\n",
    "print(save_estimator(onehotencoder  , 'estimators/encoder_oh.sav'))\n",
    "print(save_estimator(helmert_encoder, 'estimators/encoder_hel.sav'))\n",
    "\n",
    "print(save_estimator(binarizer , 'estimators/encoder_label.sav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
