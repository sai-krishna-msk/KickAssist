{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/notebooks/4_merged_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saima\\Anaconda3\\envs\\kick\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (29) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165006, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The reason we are not filling missing values with constant is because we are unlikely to make prediction in batch in test environment rather on single  instances, for this case we would not get null values in test environment**\n",
    "- **Days to Delivery is not being used as a feature because, there are significant number of null/corrupt(scraping issues) values and by further research it's been found out that creator of the campaign is not only allowed to change the date over time but is also not contingent to deliver by the provided date(which is seems to be the case more often)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['launched_at',  'status', 'days_to_deadline', 'goal',\n",
    "       'sub_category', 'category', 'blurb_length', 'location_country',  'rewards_mean', 'rewards_median',\n",
    "       'rewards_variance', 'rewards_SD', 'rewards_MIN', 'rewards_MAX' , 'rewards_NUM', 'currency', 'creator_created', 'creator_backed', 'launch_year', 'launch_month', 'deadline_year', 'deadline_month']\n",
    "df = df[cols]\n",
    "df= df.dropna(axis=0, subset=[\"rewards_MIN\"])\n",
    "df= df.dropna(axis=0, subset=[\"blurb_length\"])\n",
    "df['creator_created'].fillna(0, inplace=True)\n",
    "df['creator_backed'].fillna(0, inplace=True)\n",
    "df.sort_values(\"launched_at\" , inplace=True)\n",
    "\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"launched_at\"]  = pd.to_datetime(df[\"launched_at\"]).dt.date\n",
    "df.sort_values(\"launched_at\" , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['launched_at'] ,axis=1 , inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', inplace=True , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creator Backed feature seems to be of string type with some of them having commas let's fix that**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBakced(x):\n",
    "    try:\n",
    "        return  float(x)\n",
    "    except:\n",
    "        return float(x.replace(\",\", \"\"))\n",
    "df['creator_backed'] = df[\"creator_backed\"].apply(getBakced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "binarizer= LabelBinarizer()\n",
    "df[\"status\"] = binarizer.fit_transform(df[\"status\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder  = OneHotEncoder(sparse=False)\n",
    "cat_cols=['category', 'sub_category', 'currency', 'location_country']\n",
    "X_hot = encoder.fit_transform(df[cat_cols])\n",
    "\n",
    "\n",
    "onehotcols = []\n",
    "for cat in encoder.categories_:\n",
    "    for col in cat:\n",
    "        onehotcols.append(col)\n",
    "\n",
    "X_hot = pd.DataFrame(X_hot , columns=onehotcols)\n",
    "df =pd.concat([df , X_hot] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cat_cols , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years =[2014 ,2015, 2016, 2017]\n",
    "\n",
    "valid_years = [2018]\n",
    "\n",
    "df_train = df[df['launch_year'].apply(lambda x: True if x in train_years else False)]\n",
    "df_valid= df[df['launch_year'].apply(lambda x: True if x in valid_years else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train = df_train.drop(\"status\" , axis=1) , df_train['status']\n",
    "X_valid , y_valid = df_valid.drop(\"status\" , axis=1) , df_valid['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import operator\n",
    "\n",
    "\n",
    "def score(X_train, X_test, y_train, y_test):\n",
    "    rf_fet = {}\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf= RandomForestClassifier(n_estimators=100, random_state=13579)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_score = rf.score(X_test, y_test)\n",
    "    \n",
    "   \n",
    "    feat_labels = X_train.columns.values\n",
    "    \n",
    "    for feature, acc in zip(feat_labels, rf.feature_importances_):\n",
    "        rf_fet[feature] = acc\n",
    "        \n",
    "    rf_fet =  sorted(rf_fet.items(), key=operator.itemgetter(1), reverse=True)\n",
    "  \n",
    "        \n",
    "    return (rf,rf_score, rf_fet)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8138555870778805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "_ , scores , _ = score(X_train , X_valid , y_train , y_valid)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally we have achieved 80% an acceptable accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But there are certain problems with few features**\n",
    "- Creators backed and creators created have values of the time when it was scrapped not at the time when the creator created the project this can lead to data leakage so we need to remove this column\n",
    "- Random Forest, which is the model we are using is good at interpolation but not as good with extrapolation so any feature having temporal component has negative effect on the model (So let us try removing feature like launch_month deadline_month etc)\n",
    "- We also have to discard launch year and deadline year because\n",
    "    - We would be training our model every month ideally and testing it for the next so the model would be always up-to date and not tested on previous year's data, in which case there would be no use in knowing years of launch and deadline\n",
    "    - Temporal variables are best to avoid when using Models like Random Forest as they are not good at interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['creator_created', 'creator_backed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(drop_cols , axis=1  ,inplace=True)\n",
    "X_valid.drop(drop_cols , axis=1  ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7942253134437631\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "_ , scores , _ = score(X_train , X_valid , y_train , y_valid)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After removing the columns which i speculate to cause data lekage we did not yet hit our sweet mark, let us do some EDA and see if we find some thing interesting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Before making decision about complicated feature engineering techniques it should be kept in mind that objective of our project is to make the model as interpretable and simulational(to say) as possible, so revisiting the product that we've decided upon**\n",
    "\n",
    "- **It is clear that there are some variables which are fixed by the user and  the other variable's subject to change would be exploited therefore for the reasons of Explainability let us minimize advance feature engineering and confine it to those fixed variables**\n",
    "\n",
    "- **So we can not perform some advance feature engineering techniques on the variables such that they transform into numbers which become unrecognizable**\n",
    "- **Having said that we are still free to perform Feature engineering on static categorical variables, so let us experiment with some encoding techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saima\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "df = pd.read_csv(data_path)\n",
    "df_raw = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoding_cols = ['location_country' , 'currency' , 'category', 'sub_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_smoothning(df , by , on , m):\n",
    "    mean =  df[on].mean()\n",
    "    \n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "    \n",
    "    smooth = (counts *means +m*mean) /(counts*m)\n",
    "    \n",
    "    return df[by].map(smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['launched_at',  'status', 'days_to_deadline', 'goal',\n",
    "       'sub_category', 'category', 'blurb_length', 'location_country',  'rewards_mean', 'rewards_median',\n",
    "       'rewards_variance', 'rewards_SD', 'rewards_MIN', 'rewards_MAX' , 'rewards_NUM', 'currency', 'launch_year', 'launch_month', 'deadline_month']\n",
    "df = df[cols]\n",
    "df= df.dropna(axis=0, subset=[\"rewards_MIN\"])\n",
    "df= df.dropna(axis=0, subset=[\"blurb_length\"])\n",
    "df.sort_values(\"launched_at\" , inplace=True)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df[\"launched_at\"]  = pd.to_datetime(df[\"launched_at\"]).dt.date\n",
    "df.sort_values(\"launched_at\" , inplace=True)\n",
    "\n",
    "df.drop(['launched_at'] ,axis=1 , inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', inplace=True , axis=1)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "binarizer= LabelBinarizer()\n",
    "df[\"status\"] = binarizer.fit_transform(df[\"status\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helmert_encoding(X_train , X_valid ,target_encoding_cols ):\n",
    "    encoder = ce.HelmertEncoder(cols = target_encoding_cols , drop_invariant=True )\n",
    "    dfh = encoder.fit_transform(X_train[target_encoding_cols])\n",
    "    X_train = pd.concat([X_train , dfh], axis=1)\n",
    "    X_train.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    dfh = encoder.transform(X_valid[target_encoding_cols])\n",
    "    X_valid = pd.concat([X_valid , dfh], axis=1)\n",
    "    X_valid.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    _ , scores , _ = score(X_train , X_valid , y_train , y_valid)\n",
    "    print(\"Helmert Encoding: \"+str(scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encoding(X_train , X_valid ,target_encoding_cols ):\n",
    "    encoder = ce.BinaryEncoder(cols = target_encoding_cols , drop_invariant=True )\n",
    "    dfh = encoder.fit_transform(X_train[target_encoding_cols])\n",
    "    X_train = pd.concat([X_train , dfh], axis=1)\n",
    "    X_train.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    dfh = encoder.transform(X_valid[target_encoding_cols])\n",
    "    X_valid = pd.concat([X_valid , dfh], axis=1)\n",
    "    X_valid.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    _ , scores , _ = score(X_train , X_valid , y_train , y_valid)\n",
    "    print(\"Binary Encoding: \"+str(scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_encoding(X_train , X_valid ,target_encoding_cols, y_train ):\n",
    "    encoder = ce.CatBoostEncoder(cols = target_encoding_cols  )\n",
    "    dfh = encoder.fit_transform(X_train[target_encoding_cols] , y_train)\n",
    "    X_train = pd.concat([X_train , dfh], axis=1)\n",
    "    X_train.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    dfh = encoder.transform(X_valid[target_encoding_cols])\n",
    "    X_valid = pd.concat([X_valid , dfh], axis=1)\n",
    "    X_valid.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    _ , scores , _ = score(X_train , X_valid , y_train , y_valid)\n",
    "    print(\"CatBoostEncoder: \"+str(scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_years=[2015, 2016, 2017]\n",
    "valid_years = [2018]\n",
    "df_train = df[df['launch_year'].apply(lambda x: True if x in train_years else False)]\n",
    "df_valid= df[df['launch_year'].apply(lambda x: True if x in valid_years else False)]\n",
    "X_train , y_train = df_train.drop([\"status\",\"launch_year\"] , axis=1) , df_train['status']\n",
    "X_valid , y_valid = df_valid.drop([\"status\",\"launch_year\"] , axis=1) , df_valid['status']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helmert Encoding: 0.8019584515420518\n"
     ]
    }
   ],
   "source": [
    "helmert_encoding(X_train , X_valid , target_encoding_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Encoding: 0.793264390958177\n"
     ]
    }
   ],
   "source": [
    "binary_encoding(X_train , X_valid ,target_encoding_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostEncoder: 0.7433879381348952\n"
     ]
    }
   ],
   "source": [
    "cat_encoding(X_train , X_valid ,target_encoding_cols , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Unkown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **There is actually one thing we need to make sure which comes up during production of the model, which is to handle unknown categorical variables(We already handled outliers and missing values)**\n",
    "- **Since the way we handle them would impact the model we need to do it before hyperparameter optimization and model selection**\n",
    "- **As encoding categorical variables is being carried out by herlmert encoder, let's see how it handles it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.HelmertEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>0_0</th>\n",
       "      <th>0_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intercept  0_0  0_1\n",
       "0          1 -1.0 -1.0\n",
       "1          1  1.0 -1.0\n",
       "2          1  0.0  2.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit_transform(['statistics', 'datascience', 'machine learning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>0_0</th>\n",
       "      <th>0_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intercept  0_0  0_1\n",
       "0          1  0.0  0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.transform(['deeplearning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **As we can see above it does not throw error so we would not have any problem in production**\n",
    "- **Probability of having new category is low anyways so it is not something to worry about**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Finally we've achieved acceptable score of 80% with Helmert Encoding**\n",
    "\n",
    "- **But for interpretibility reasons we will also have to include one_hot_encoding(You will as to why that is further down the post)**\n",
    "\n",
    "- **There are plenty of feature engineering we could have done which would have boosted the accuracy of the model but that would transform our features such that it would not be possible to interpret which in-turn does not align with our business objective**\n",
    "\n",
    "\n",
    "\n",
    "- **Till now we have been trying out just Random Forest, in the next notebook let us try XGboost in the next notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
