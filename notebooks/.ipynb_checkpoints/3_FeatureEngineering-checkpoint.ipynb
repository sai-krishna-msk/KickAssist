{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =\"C:/Users/saima/Desktop/kickstarter/CrowdFunding/Data/dataset/2-clean-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw =pd.read_csv(data_path)\n",
    "df_raw['launched_at'] = pd.to_datetime(df_raw['launched_at'])\n",
    "df_raw['deadline'] = pd.to_datetime(df_raw['deadline'])\n",
    "df_raw['state_changed_at'] = pd.to_datetime(df_raw['state_changed_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index().drop(['index', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blurb\n",
    "\n",
    "*Description*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use description as feature\n",
    "- We can add the length of text \n",
    "- We can perform some basic text processing(tokenization->lematization ->tfidf) and include as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blurb_length(x):\n",
    "    try:\n",
    "        return len(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['blurb_length'] = df['blurb'].apply(get_blurb_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['launched_at', 'deadline', 'status', 'goal',\n",
    "       'sub_category', 'category', 'blurb_length', 'location_country',  'currency']\n",
    "df = df[cols]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "df.sort_values(\"launched_at\" , inplace=True)\n",
    "\n",
    "df = df.reindex()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"launched_at\"]  = pd.to_datetime(df[\"launched_at\"])\n",
    "df[\"launched_year\"]  = pd.to_datetime(df[\"launched_at\"]).dt.year\n",
    "df['launch_month'] = df['launched_at'].dt.month\n",
    "\n",
    "df['deadline'] = pd.to_datetime(df['deadline'])\n",
    "df['deadline_year'] = pd.to_datetime(df['deadline']).dt.year\n",
    "df['deadline_month'] = pd.to_datetime(df['deadline']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df.drop(['launched_at', 'deadline'] ,axis=1 , inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', inplace=True , axis=1)\n",
    "\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    binarizer= LabelBinarizer()\n",
    "    df[\"status\"] = binarizer.fit_transform(df[\"status\"])\n",
    "    \n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    encoder  = OneHotEncoder(sparse=False)\n",
    "    cat_cols=['category', 'sub_category', 'currency', 'location_country']\n",
    "    X_hot = encoder.fit_transform(df[cat_cols])\n",
    "    \n",
    "    \n",
    "    onehotcols = []\n",
    "    for cat in encoder.categories_:\n",
    "        for col in cat:\n",
    "            onehotcols.append(col)\n",
    "            \n",
    "    X_hot = pd.DataFrame(X_hot , columns=onehotcols)\n",
    "    df =pd.concat([df , X_hot] , axis=1)\n",
    "    df.drop(cat_cols , axis=1 , inplace=True)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(df, train_years , valid_years):\n",
    "    df_train = df[df['launched_year'].apply(lambda x: True if x in train_years else False)]\n",
    "    df_valid= df[df['launched_year'].apply(lambda x: True if x in valid_years else False)]\n",
    "    \n",
    "    X_train , y_train = df_train.drop(\"status\" , axis=1) , df_train['status']\n",
    "    X_valid , y_valid = df_valid.drop(\"status\" , axis=1) , df_valid['status']\n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_valid , y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import operator\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "def score(X_train, X_test, y_train, y_test):\n",
    "    rf_fet = {}\n",
    "    gb_fet = {}\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf= RandomForestClassifier(n_estimators=100, random_state=13579)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_score = rf.score(X_test, y_test)\n",
    "    \n",
    "   \n",
    "    feat_labels = X_train.columns.values\n",
    "    \n",
    "    for feature, acc in zip(feat_labels, rf.feature_importances_):\n",
    "        rf_fet[feature] = acc\n",
    "        \n",
    "    rf_fet =  sorted(rf_fet.items(), key=operator.itemgetter(1), reverse=True)\n",
    "  \n",
    "        \n",
    "    return (rf,rf_score, rf_fet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years =[2009, 2010 , 2011, 2012 , 2013 , 2014 ,2015, 2016, 2017]\n",
    "valid_years = [2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7170204100104086\n"
     ]
    }
   ],
   "source": [
    "df_transformed = transform(df)\n",
    "X_train, y_train , X_valid , y_valid = get_model_data(df_transformed , train_years , valid_years)\n",
    "_ , scores , _ = score(X_train , X_valid , y_train , y_valid)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see there is a slight improovement in the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadline\n",
    "\n",
    "- We can add features like days_to_deadline , indicating number of days to deadline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_to_deadline'] = (df['deadline'] - df['launched_at']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-415381f49318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_transformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "df_transformed = transform(df)\n",
    "X_train, y_train , X_valid , y_valid = get_model_data(df_transformed)\n",
    "_ , scores , _ = score(X_train , X_valid , y_train , y_valid)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy of the model increased by about 2% which is great\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets check how good our random forest is doing compared to Logistic Regerssion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "def logistic_score(X_train , y_train , X_valid , y_valid):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train , y_train)\n",
    "    \n",
    "    return model.score(X_valid , y_valid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logistic_score(X_train , y_train , X_valid , y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Though 73% is not bad, its still not 80%, so i guess we've got to revisit our domain knowledge**\n",
    "\n",
    "- There we can see that structure of the rewards matter significantly so let's visit the website and see what we can do(scrpae)\n",
    "\n",
    "<img src=\"images/scrape.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see above html elements containing the rewards are present in the form of distinct cards which means they can be scrapped(tunrs out they can be)\n",
    "\n",
    "- While i was searhcing for some other things i could extract which would add value, i came across delivery dates(which is Expected month of delivery of rewards), Well putting yourself in the shoes of someone looking for backing the project for rewards that would definitly influence you opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the domain knowledge section we can see social media presence and marketing as an important factor for success(though we an get crazy and start scraping twitter, reddit etc, for the product's digital presence\n",
    "- I actually found something which also could be of help, which is experience of the creator in the form of number of projects backed and number of projects created, \n",
    "\n",
    "<img src=\"images/creator_info.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Though this can not be directly attributed to social presence but we can assume that more the experince of the creator better would be his/her skills of marketing\n",
    "- So i also decided to scrape that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To round up following are information for each project i would be scrapping**\n",
    "- Rewards\n",
    "- Delivery date\n",
    "- Number of projects creator has previosuly created and has backed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can check out the scraping scripts in the scrape_scripts folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us save the dataset for future use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw =pd.read_csv(data_path)\n",
    "df_raw['launched_at'] = pd.to_datetime(df_raw['launched_at'])\n",
    "df_raw['deadline'] = pd.to_datetime(df_raw['deadline'])\n",
    "df_raw['state_changed_at'] = pd.to_datetime(df_raw['state_changed_at'])\n",
    "\n",
    "df = df_raw.copy()\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index().drop(['index', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "def get_blurb_length(x):\n",
    "    try:\n",
    "        return len(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "df['blurb_length'] = df['blurb'].apply(get_blurb_length)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.sort_values(\"launched_at\" , inplace=True)\n",
    "\n",
    "df = df.reindex()\n",
    "\n",
    "\n",
    "df[\"launched_at\"]  = pd.to_datetime(df[\"launched_at\"])\n",
    "df[\"launch_year\"]  = pd.to_datetime(df[\"launched_at\"]).dt.year\n",
    "df['launch_month'] = df['launched_at'].dt.month\n",
    "\n",
    "df['deadline'] = pd.to_datetime(df['deadline'])\n",
    "df['deadline_year'] = pd.to_datetime(df['deadline']).dt.year\n",
    "df['deadline_month'] = pd.to_datetime(df['deadline']).dt.month\n",
    "\n",
    "\n",
    "\n",
    "df['days_to_deadline'] = (df['deadline'] - df['launched_at']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/saima/Desktop/kickstarter/CrowdFunding/Data/dataset/3_feature_engineerd_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
