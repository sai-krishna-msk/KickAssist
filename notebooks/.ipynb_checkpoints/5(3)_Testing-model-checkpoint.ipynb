{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Let us see how well our model would perform if we would deploy our model at the end of 2018**\n",
    "- **ie: Let us test our model on 2019 data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import  category_encoders as ce\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/notebooks/4_merged_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saima\\Anaconda3\\envs\\kick\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (29) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['launched_at', 'status', 'days_to_deadline', 'goal',\n",
    "       'sub_category', 'category', 'blurb_length', 'location_country',  'rewards_mean', 'rewards_median',\n",
    "       'rewards_variance', 'rewards_SD', 'rewards_MIN', 'rewards_MAX' ,\n",
    "        'rewards_NUM', 'currency', 'launch_year', 'launch_month',\n",
    "         'deadline_month']\n",
    "target_encoding_cols = ['location_country' , 'currency' , 'category', 'sub_category']\n",
    "\n",
    "train_years =[ 2016, 2017  , 2018]\n",
    "valid_years = [2019]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_proc(df):\n",
    "    df = df[cols]\n",
    "    df= df.dropna(axis=0, subset=[\"rewards_MIN\"])\n",
    "    df= df.dropna(axis=0, subset=[\"blurb_length\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"launched_at\"]  = pd.to_datetime(df[\"launched_at\"]).dt.date\n",
    "    df.sort_values(\"launched_at\" , inplace=True)\n",
    "    df.drop(['launched_at'] ,axis=1 , inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', inplace=True , axis=1)\n",
    "    \n",
    "    binarizer= LabelBinarizer()\n",
    "    df[\"status\"] = binarizer.fit_transform(df[\"status\"])\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_categ(df):\n",
    "    \n",
    "    encoder  = OneHotEncoder(sparse=False)\n",
    "    cat_cols=['category', 'sub_category', 'currency', 'location_country']\n",
    "    X_hot = encoder.fit_transform(df[cat_cols])\n",
    "    \n",
    "    onehotcols = []\n",
    "    for cat in encoder.categories_:\n",
    "        for col in cat:\n",
    "            onehotcols.append(col)\n",
    "            \n",
    "    X_hot = pd.DataFrame(X_hot , columns=onehotcols)\n",
    "    df =pd.concat([df , X_hot] , axis=1)\n",
    "    df.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    \n",
    "    \n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(df , train_years , valid_years):\n",
    "    df_train = df[df['launch_year'].apply(lambda x: True if x in train_years else False)]\n",
    "    df_valid= df[df['launch_year'].apply(lambda x: True if x in valid_years else False)]\n",
    "    \n",
    "    X_train , y_train = df_train.drop([\"status\",\"launch_year\"] , axis=1) , df_train['status']\n",
    "    X_valid , y_valid = df_valid.drop([\"status\",\"launch_year\"] , axis=1) , df_valid['status']\n",
    "    \n",
    "    return X_train , y_train , X_valid , y_valid\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helmert_categ(df_train , df_valid):\n",
    "    encoder = ce.HelmertEncoder(cols = target_encoding_cols , drop_invariant=True )\n",
    "    dfh = encoder.fit_transform(df_train[target_encoding_cols])\n",
    "    df_train = pd.concat([df_train , dfh], axis=1)\n",
    "    df_train.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    dfh = encoder.transform(df_valid[target_encoding_cols])\n",
    "    df_valid = pd.concat([df_valid , dfh], axis=1)\n",
    "    df_valid.drop(target_encoding_cols , axis=1 , inplace=True)\n",
    "    \n",
    "    return df_train , df_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import operator\n",
    "\n",
    "def XG_score(X_train, X_test, y_train, y_test):\n",
    "    XG_fet = {}\n",
    "    \n",
    "    XG= XGBClassifier(n_estimators=150, random_state=9)\n",
    "    XG.fit(X_train, y_train)\n",
    "    XG_score = XG.score(X_test, y_test)\n",
    "    \n",
    "   \n",
    "    feat_labels = X_train.columns.values\n",
    "    \n",
    "    for feature, acc in zip(feat_labels, XG.feature_importances_):\n",
    "        XG_fet[feature] = acc\n",
    "        \n",
    "    XG_fet =  sorted(XG_fet.items(), key=operator.itemgetter(1), reverse=True)\n",
    "  \n",
    "        \n",
    "    return (XG,XG_score, XG_fet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc  = pre_proc(df)\n",
    "df_onehot   = onehot_categ(df_proc)\n",
    "X_train_oh , y_train_oh , X_valid_oh , y_valid_oh  = get_model_data(df_onehot , train_years , valid_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc  = pre_proc(df)\n",
    "X_train_raw , y_train_hel , X_valid_raw , y_valid_hel  = get_model_data(df_proc , train_years , valid_years)\n",
    "X_train_hel , X_valid_hel   = helmert_categ(X_train_raw , X_valid_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score using OneHot encodinng: 0.8151040114442392\n"
     ]
    }
   ],
   "source": [
    "XG_model_oh , XG_scores_oh , XG_fet_imp_oh= XG_score(X_train_oh , X_valid_oh , y_train_oh , y_valid_oh)\n",
    "print(\"Score using OneHot encodinng: {}\".format(XG_scores_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score using Helmert encodinng: 0.8627287357692078\n"
     ]
    }
   ],
   "source": [
    "XG_model_hel , XG_scores_hel , XG_fet_imp_hel= XG_score(X_train_hel , X_valid_hel , y_train_hel , y_valid_hel)\n",
    "print(\"Score using Helmert encodinng: {}\".format(XG_scores_hel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **This should is great, our test accuracy is greater than our validation accuracy, usually this should be a red flag but since there was not decision during the process of modeling and preprocessing made based off the 2019(test data), its fine**\n",
    "- **In the next notebook we will train the model on the entire dataset and save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
